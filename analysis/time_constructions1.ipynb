{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Constructions\n",
    "\n",
    "Towards a usage-based, constructional taxonomy of time indicators in Biblical Hebrew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.4.11\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "143 features found and 4 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.13s B g_cons_utf8          from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.09s B lex                  from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |      |     0.94s C __levels__           from otype, oslots, otext\n",
      "   |      |       16s C __order__            from otype, oslots, __levels__\n",
      "   |      |     0.88s C __rank__             from otype, __order__\n",
      "   |      |       14s C __levUp__            from otype, oslots, __levels__, __rank__\n",
      "   |      |       12s C __levDown__          from otype, __levUp__, __rank__\n",
      "   |      |     3.27s C __boundary__         from otype, oslots, __rank__\n",
      "   |      |     0.09s C __sections__         from otype, oslots, otext, __levUp__, __levels__, book, chapter, verse\n",
      "   |     0.09s B vs                   from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.09s B vt                   from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.08s B pdp                  from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.10s B gloss                from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.07s B language             from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.14s B rela                 from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.13s B typ                  from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.17s B number               from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     1.14s T function             from /Users/cody/github/csl/time_collocations/data\n",
      "   |     0.10s B prs                  from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.09s B nu                   from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.20s B mother               from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.08s B st                   from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.10s B uvf                  from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.31s B head                 from /Users/cody/github/etcbc/heads/tf/c\n",
      "   |     0.42s B nhead                from /Users/cody/github/etcbc/heads/tf/c\n",
      "   |     0.04s B obj_prep             from /Users/cody/github/etcbc/heads/tf/c\n",
      "   |     0.02s B sem_set              from /Users/cody/github/etcbc/heads/tf/c\n",
      "   |     0.10s B ls                   from /Users/cody/text-fabric-data/etcbc/bhsa/tf/c\n",
      "   |     0.11s B topAssoc             from /Users/cody/github/csl/time_collocations/data/funct_associations\n",
      "   |     0.07s B TimeAssoc            from /Users/cody/github/csl/time_collocations/data/funct_associations\n",
      "   |     0.06s B LocaAssoc            from /Users/cody/github/csl/time_collocations/data/funct_associations\n",
      "   |     0.15s T label                from /Users/cody/github/csl/time_collocations/data\n",
      "   |     0.01s T role                 from /Users/cody/github/csl/time_collocations/data\n",
      " 1m 03s All features loaded/computed - for details use loadLog()\n",
      "TF app is up-to-date.\n",
      "Using annotation/app-bhsa commit 78de65f21cdaae29c46231bcfa0b72a0552fb882 (=latest)\n",
      "  in /Users/cody/text-fabric-data/__apps__/bhsa.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "@font-face {\n",
       "  font-family: \"Ezra SIL\";\n",
       "  src:\n",
       "    local(\"SILEOT.ttf\"),\n",
       "    url(\"https://github.com/annotation/text-fabric/blob/master/tf/server/static/fonts/SILEOT.woff?raw=true\");\n",
       "}\n",
       ".features {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0a6611;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    direction: ltr;\n",
       "}\n",
       ".features div,.features span {\n",
       "    padding: 0;\n",
       "    margin: -0.1rem 0;\n",
       "}\n",
       ".features .f {\n",
       "    font-family: sans-serif;\n",
       "    font-size: x-small;\n",
       "    font-weight: normal;\n",
       "    color: #5555bb;\n",
       "}\n",
       ".features .xft {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-size: medium;\n",
       "  margin: 0.1em 0em;\n",
       "}\n",
       ".features .xft .f {\n",
       "  color: #000000;\n",
       "  background-color: #eeeeee;\n",
       "  font-style: italic;\n",
       "  font-size: small;\n",
       "  font-weight: normal;\n",
       "}\n",
       ".ltr {\n",
       "    direction: ltr ! important;\n",
       "}\n",
       ".verse {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".vl {\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    justify-content: flex-end;\n",
       "    align-items: flex-end;\n",
       "    direction: ltr;\n",
       "    width: 100%;\n",
       "}\n",
       ".outeritem {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    direction: rtl;\n",
       "}\n",
       ".sentence,.clause,.phrase {\n",
       "    margin-top: -1.2em;\n",
       "    margin-left: 1em;\n",
       "    background: #ffffff none repeat scroll 0 0;\n",
       "    padding: 0 0.3em;\n",
       "    border-style: solid;\n",
       "    border-radius: 0.2em;\n",
       "    font-size: small;\n",
       "    display: block;\n",
       "    width: fit-content;\n",
       "    max-width: fit-content;\n",
       "    direction: ltr;\n",
       "}\n",
       ".atoms {\n",
       "    display: flex;\n",
       "    flex-flow: row wrap;\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".satom,.catom,.patom {\n",
       "    margin: 0.3em;\n",
       "    padding: 0.3em;\n",
       "    border-radius: 0.3em;\n",
       "    border-style: solid;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".sentence {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".clause {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".phrase {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 1px;\n",
       "}\n",
       ".satom {\n",
       "    border-color: #aa3333;\n",
       "    border-width: 4px;\n",
       "}\n",
       ".catom {\n",
       "    border-color: #aaaa33;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".patom {\n",
       "    border-color: #33aaaa;\n",
       "    border-width: 3px;\n",
       "}\n",
       ".word {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 1px solid #cccccc;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".lextp {\n",
       "    padding: 0.1em;\n",
       "    margin: 0.1em;\n",
       "    border-radius: 0.1em;\n",
       "    border: 2px solid #888888;\n",
       "    width: fit-content;\n",
       "    display: flex;\n",
       "    flex-flow: column nowrap;\n",
       "    direction: rtl;\n",
       "    background-color: #ffffff;\n",
       "}\n",
       ".occs {\n",
       "    font-size: x-small;\n",
       "}\n",
       ".satom.l,.catom.l,.patom.l {\n",
       "    border-left-style: dotted\n",
       "}\n",
       ".satom.r,.catom.r,.patom.r {\n",
       "    border-right-style: dotted\n",
       "}\n",
       ".satom.lno,.catom.lno,.patom.lno {\n",
       "    border-left-style: none\n",
       "}\n",
       ".satom.rno,.catom.rno,.patom.rno {\n",
       "    border-right-style: none\n",
       "}\n",
       ".tr,.tr a:visited,.tr a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".trb,.trb a:visited,.trb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: normal;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".prb,.prb a:visited,.prb a:link {\n",
       "    font-family: sans-serif;\n",
       "    font-size: large;\n",
       "    direction: ltr;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".h,.h a:visited,.h a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    color: #000044;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".hb,.hb a:visited,.hb a:link {\n",
       "    font-family: \"Ezra SIL\", \"SBL Hebrew\", sans-serif;\n",
       "    font-size: large;\n",
       "    line-height: 2;\n",
       "    direction: rtl;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".vn {\n",
       "  font-size: small !important;\n",
       "  padding-right: 1em;\n",
       "}\n",
       ".rela,.function,.typ {\n",
       "    font-family: monospace;\n",
       "    font-size: small;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".pdp,.pdp a:visited,.pdp a:link {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "    text-decoration: none;\n",
       "}\n",
       ".voc_lex {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vs {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".vt {\n",
       "    font-family: monospace;\n",
       "    font-size: medium;\n",
       "    font-weight: bold;\n",
       "    color: #0000bb;\n",
       "}\n",
       ".gloss {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: normal;\n",
       "    color: #444444;\n",
       "}\n",
       ".vrs {\n",
       "    font-family: sans-serif;\n",
       "    font-size: small;\n",
       "    font-weight: bold;\n",
       "    color: #444444;\n",
       "}\n",
       ".nd {\n",
       "    font-family: monospace;\n",
       "    font-size: x-small;\n",
       "    color: #999999;\n",
       "}\n",
       ".hl {\n",
       "    background-color: #ffee66;\n",
       "}\n",
       "span.hldot {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder: 0.2rem solid var(--hl-rim);\n",
       "\tborder-radius: 0.4rem;\n",
       "\t/*\n",
       "\tdisplay: inline-block;\n",
       "\twidth: 0.8rem;\n",
       "\theight: 0.8rem;\n",
       "\t*/\n",
       "}\n",
       "span.hl {\n",
       "\tbackground-color: var(--hl-strong);\n",
       "\tborder-width: 0;\n",
       "\tborder-radius: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "}\n",
       "\n",
       "span.hlup {\n",
       "\tborder-color: var(--hl-dark);\n",
       "\tborder-width: 0.1rem;\n",
       "\tborder-style: solid;\n",
       "\tborder-radius: 0.2rem;\n",
       "  padding: 0.2rem;\n",
       "}\n",
       "\n",
       ":root {\n",
       "\t--hl-strong:        hsla( 60, 100%,  70%, 0.9  );\n",
       "\t--hl-rim:           hsla( 55, 100%,  60%, 0.9  );\n",
       "\t--hl-dark:          hsla( 55, 100%,  40%, 0.9  );\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections, csv, random\n",
    "from textwrap import indent\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.5, style='whitegrid')\n",
    "import matplotlib.pyplot as plt\n",
    "from pyscripts.significance import contingency_table, apply_fishers\n",
    "from tf.fabric import Fabric\n",
    "from tf.app import use\n",
    "\n",
    "custom_data = ['/Users/cody/text-fabric-data/etcbc/bhsa/tf/c',\n",
    "               '/Users/cody/github/etcbc/heads/tf/c',\n",
    "               '../data/',\n",
    "               '../data/funct_associations/'\n",
    "              ]\n",
    "\n",
    "TF = Fabric(locations=custom_data)\n",
    "api = TF.load('''\n",
    "\n",
    "vs vt pdp gloss lex language \n",
    "rela typ number function prs\n",
    "g_cons_utf8 nu mother st uvf\n",
    "head nhead obj_prep sem_set\n",
    "ls topAssoc TimeAssoc LocaAssoc\n",
    "label role\n",
    "''')\n",
    "\n",
    "A = use('bhsa', api=api, hoist=globals(), silent=True)\n",
    "\n",
    "A.displaySetup(condenseType='clause', condensed=True, withNodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLex(lex_str):\n",
    "    '''\n",
    "    Finds a lex node.\n",
    "    '''\n",
    "    return [(l, F.gloss.v(l), F.lex.v(l)) \n",
    "                for l in F.otype.s('lex')\n",
    "                if lex_str == F.lex.v(l)]\n",
    "\n",
    "def flattenNodes(nodeList):\n",
    "    '''\n",
    "    Takes any list of mixed node types\n",
    "    and flattens them to a list of slots.\n",
    "    '''\n",
    "    slots = []\n",
    "    for n in nodeList:\n",
    "        if F.otype.v(n) == 'word':\n",
    "            slots.append(n)\n",
    "        else:\n",
    "            slots.extend(L.d(n, 'word'))\n",
    "    return sorted(set(slots))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization Strategy\n",
    "\n",
    "One of the goals in this analysis is to see broad tendencies which various constructions of time have in common. Tokenization is a data-oriented way to create sets of similar forms. For instance, the quantifier NP construction is ubiquitous within time constructions. Rather than tokenizing the individual parts of that construction, such as the number lexeme, connecting waws, or the quantified noun, it is better that the whole quantified expression be tokenized as a single unit.\n",
    "\n",
    "This actually presents a difficult programming challenge: how to know when to tokenize a word with lexical content and when to do so with a particular tag? If we tag an entire quantifier construction with a tag, the algorithm should recognize that it should not tokenize the component words. Furthermore, the system needs to be extendable, so that additional filters can be added as needed. \n",
    "\n",
    "The solution comes by mapping the first word of a construction to a set of skip words. For every unit above the word level, we add the first word as a key to a dictionary. The value is another dictionary which contains both a token and skip-words. The skip-words contain the rest of the construction, which are added to a skip-set. For every time phrase, all words are iterated over. Those words that are in the token dictionary will trigger the token and the addition of skip words. The algorithm will then skip over words that follow that word as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86657"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customtokens = {} # For each slot, record its labelâ€”if not 1st slot in larger object, record empty label of ''\n",
    "slot2node = {} # For each label, keep track of its representative node\n",
    "\n",
    "# first map tokens for all objects > word\n",
    "# map first word to token, map all subsequent words in object to empty string\n",
    "\n",
    "# map tokens for highest level quantifier constructions\n",
    "for qc in F.label.s('quant_NP') + F.label.s('quant_NP_chain'):\n",
    "    # skip embedded constructions\n",
    "    if [qc for qc in L.u(qc, 'construction') if F.label.v(qc) == 'quant_NP_chain']:\n",
    "        continue\n",
    "    qc_words = L.d(qc, 'word')\n",
    "    customtokens[qc_words[0]] = 'quantNP'\n",
    "    slot2node[qc_words[0]] = qc\n",
    "    customtokens.update(dict((w, '') for w in qc_words[1:])) # add blank tokens for remaining terms\n",
    "    \n",
    "# map preposition chunks to prep token\n",
    "# a \"chunk\" is when prepositions are stacked\n",
    "for pc in F.label.s('prep'):\n",
    "    pc_words = L.d(pc, 'word')\n",
    "    customtokens[pc_words[0]]  = 'prep'\n",
    "    slot2node[pc_words[0]] = pc\n",
    "    customtokens.update(dict((w, '') for w in pc_words[1:])) # blank tokens\n",
    "    \n",
    "# now add word tokens, checking to make sure they're not already accounted for\n",
    "    \n",
    "# all words in time phrases\n",
    "tp_words = [w for tp in F.otype.s('phrase2') \n",
    "                if F.function.v(tp) == 'Time'\n",
    "                for w in L.d(tp, 'word')]\n",
    "    \n",
    "for word in tp_words:\n",
    "\n",
    "    # skip words already tokenized\n",
    "    if word in customtokens:\n",
    "        continue\n",
    "        \n",
    "    # token articles\n",
    "    elif F.lex.v(word) == 'H':\n",
    "        customtokens[word] = 'H'\n",
    "\n",
    "    # token ordinals\n",
    "    elif F.ls.v(word) == 'ordn':\n",
    "        customtokens[word] = 'ordn'\n",
    "\n",
    "    # token qualitative quantifiers\n",
    "    elif (F.sem_set.v(word) == 'quant') and (not F.ls.v(word) == 'card'):\n",
    "        customtokens[word] = 'qualQuant'\n",
    "    \n",
    "    # token head words \n",
    "    elif E.nhead.f(word):\n",
    "        customtokens[word] = 'time'\n",
    "\n",
    "    # token demonstratives\n",
    "    elif F.pdp.v(word) == 'prde':\n",
    "        customtokens[word] = 'dem'\n",
    "    \n",
    "    # token likely adjuncts\n",
    "    elif F.pdp.v(word) in {'subs', 'adjv'}:\n",
    "        customtokens[word] = 'adju'\n",
    "        \n",
    "    # label will be subsumed under single word\n",
    "    slot2node[word] = word\n",
    "        \n",
    "len(customtokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to tokenize phrases..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizeWord(slot):\n",
    "    '''\n",
    "    Tokenizes a single slot.\n",
    "    '''\n",
    "    return customtokens.get(slot, F.pdp.v(slot))\n",
    "\n",
    "def tokenizePhrase(phrasenode):\n",
    "    '''\n",
    "    Maps words either to standard token\n",
    "    or to custom token based on token dictionary.\n",
    "    Returns a full token string for the phrase.\n",
    "    '''\n",
    "    \n",
    "    minitokens = [tokenizeWord(word) for word in L.d(phrasenode, 'word')]\n",
    "    minitokens = [tok for tok in minitokens if tok] # filter out empty strings\n",
    "    return '.'.join(minitokens)\n",
    "\n",
    "def buildTimeConstruction(phrasenode, cxNode):\n",
    "    '''\n",
    "    Tokenizes words based on customtokens dict\n",
    "    and assigns semantic roles based on \n",
    "    '''\n",
    "    subtokens = []\n",
    "    semroles = collections.defaultdict(dict)\n",
    "    \n",
    "    for word in L.d(phrasenode, 'word'):\n",
    "        subtoken = tokenizeWord(word)\n",
    "        subtokens.append(subtoken)\n",
    "        rolenode = slot2node.get(word, None)\n",
    "        if rolenode:\n",
    "            edgeFeatures['role'][rolenode][cxNode] = subtoken\n",
    "    \n",
    "    # build construction data\n",
    "    subtokens = [st for st in subtokens if st] # remove empty token strings\n",
    "    label = '.'.join(subtokens)\n",
    "    nodeFeatures['otype'][cxNode] = 'construction'\n",
    "    nodeFeatures['label'][cxNode] = label\n",
    "    edgeFeatures['oslots'][cxNode] = L.d(phrase, 'word')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare to Write Construction Objects\n",
    "\n",
    "Previously calculated database features are loaded so they are included in eventual export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgeFeatures = collections.defaultdict(lambda:collections.defaultdict())\n",
    "nodeFeatures = collections.defaultdict(lambda:collections.defaultdict())\n",
    "node = max(N())\n",
    "\n",
    "# add previously calculated features\n",
    "nodeFeatures['otype'] = dict((n, F.otype.v(n)) for n in N())\n",
    "edgeFeatures['oslots'] = dict((n, L.d(n, 'word')) for n in N() if F.otype.v(n) != 'word')\n",
    "nodeFeatures['label'] = dict((n, F.label.v(n)) for n in N() if F.label.v(n))\n",
    "edgeFeatures['role'] = collections.defaultdict(lambda:collections.defaultdict())\n",
    "\n",
    "for n in N():\n",
    "    for mother, role in E.role.f(n):\n",
    "        edgeFeatures['role'][n][mother] = role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2152, 2154, 2155, 2201, 2202, 2204, 2205, 2217, 2218, 2220]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(edgeFeatures['role'].keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(None, {1699935: 'quantifier'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edgeFeatures['role'][2152]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Time Phrase Dispersion\n",
    "\n",
    "This analysis of time constructions is based on frequency. In a usage-based approach to language, highly frequent terms are the prototypes which other structures in the language are based on. In the analysis of time constructions, the top occurring surface forms, or tokens, are proposed to represent the primary means of representing time. However, raw frequencies can be misleading. For this reason, we apply a frequency adjustment as suggested by Stefan Gries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.56s 3376 results\n"
     ]
    }
   ],
   "source": [
    "time_tokens = collections.defaultdict(lambda:collections.Counter())\n",
    "time_phrases = set()\n",
    "explore2results = collections.defaultdict(list)\n",
    "\n",
    "times = A.search('''\n",
    "\n",
    "phrase2 function=Time\n",
    "/without/\n",
    "    word lex=>K|>Z|<TH|KN\n",
    "/-/\n",
    "    word language=Hebrew\n",
    "\n",
    "''', shallow=True)\n",
    "\n",
    "for tp in times:\n",
    "    token = tokenizePhrase(tp)\n",
    "    book, chapter, verse = T.sectionFromNode(tp)\n",
    "    time_tokens[book][token] += 1\n",
    "    explore2results[token].append((tp,))\n",
    "    time_phrases.add(tp)\n",
    "    \n",
    "time_tokens = pd.DataFrame(time_tokens).fillna(0)\n",
    "timetok_summary = pd.DataFrame(time_tokens.sum(1).sort_values(ascending=False), columns=['sum'])\n",
    "\n",
    "\n",
    "# # count all phrase tokens in all books\n",
    "# phrase_tokens = collections.defaultdict(lambda:collections.Counter())\n",
    "\n",
    "# for phrase in F.otype.s('phrase'):\n",
    "#     book, chapter, verse = T.sectionFromNode(phrase)\n",
    "#     phrase_tokens[book][tokenPhrase(phrase)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timetok_summary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prep.time</th>\n",
       "      <td>549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.H.time.H.dem</th>\n",
       "      <td>428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantNP</th>\n",
       "      <td>325.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.H.time</th>\n",
       "      <td>307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H.time</th>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.time.adju</th>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.H.time.H.ordn</th>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualQuant.H.time</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.quantNP</th>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.time.H.adju</th>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep</th>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H.time.H.dem</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualQuant.time.adju</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time.conj.time</th>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualQuant.time</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.qualQuant.time</th>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.time.nmpr</th>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time.qualQuant</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.time.conj.time</th>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.qualQuant.H.time.H.dem</th>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.time.prep.adju</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time.adju</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.H.time.prep.H.time</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.H.ordn</th>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.time.quantNP.prep.nmpr.adju.nmpr</th>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.time.adju.prep.nmpr.adju.nmpr</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.H.time.conj.prep.H.time</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advb.prep.H.time.H.dem</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.time.nmpr.adju.nmpr</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         sum\n",
       "prep.time                              549.0\n",
       "prep.H.time.H.dem                      428.0\n",
       "quantNP                                325.0\n",
       "prep.H.time                            307.0\n",
       "H.time                                 215.0\n",
       "time                                   209.0\n",
       "prep.time.adju                         152.0\n",
       "prep.H.time.H.ordn                     147.0\n",
       "qualQuant.H.time                       100.0\n",
       "prep.quantNP                            63.0\n",
       "prep.time.H.adju                        56.0\n",
       "prep                                    33.0\n",
       "H.time.H.dem                            30.0\n",
       "qualQuant.time.adju                     30.0\n",
       "time.conj.time                          28.0\n",
       "qualQuant.time                          27.0\n",
       "prep.qualQuant.time                     26.0\n",
       "prep.time.nmpr                          25.0\n",
       "time.qualQuant                          20.0\n",
       "prep.time.conj.time                     20.0\n",
       "prep.qualQuant.H.time.H.dem             17.0\n",
       "prep.time.prep.adju                     15.0\n",
       "time.adju                               14.0\n",
       "prep.H.time.prep.H.time                 14.0\n",
       "prep.H.ordn                             14.0\n",
       "prep.time.quantNP.prep.nmpr.adju.nmpr   13.0\n",
       "prep.time.adju.prep.nmpr.adju.nmpr       9.0\n",
       "prep.H.time.conj.prep.H.time             9.0\n",
       "advb.prep.H.time.H.dem                   8.0\n",
       "prep.time.nmpr.adju.nmpr                 8.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timetok_summary.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(timetok_summary['sum'].values[:50])\n",
    "plt.title('Top Contains Majority of Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total number of time phrases accounted for in top 11 tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2551.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timetok_summary['sum'][:11].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, this is 75% of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.755627962085308"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timetok_summary['sum'][:11].sum() / len(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are those tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prep.time</th>\n",
       "      <td>549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.H.time.H.dem</th>\n",
       "      <td>428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantNP</th>\n",
       "      <td>325.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.H.time</th>\n",
       "      <td>307.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H.time</th>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>209.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.time.adju</th>\n",
       "      <td>152.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.H.time.H.ordn</th>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qualQuant.H.time</th>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.quantNP</th>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.time.H.adju</th>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep</th>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      sum\n",
       "prep.time           549.0\n",
       "prep.H.time.H.dem   428.0\n",
       "quantNP             325.0\n",
       "prep.H.time         307.0\n",
       "H.time              215.0\n",
       "time                209.0\n",
       "prep.time.adju      152.0\n",
       "prep.H.time.H.ordn  147.0\n",
       "qualQuant.H.time    100.0\n",
       "prep.quantNP         63.0\n",
       "prep.time.H.adju     56.0\n",
       "prep                 33.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timetok_summary[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "showme = explore2results['prep.time']\n",
    "\n",
    "#A.show([L.d(res[0]) for res in showme], end=20, condenseType='sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Construction Patterns\n",
    "\n",
    "The patterns above are exported for closer analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for phrase in sorted(times):\n",
    "    node += 1\n",
    "    buildTimeConstruction(phrase, node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 7.4.11\n",
      "Api reference : https://annotation.github.io/text-fabric/Api/Fabric/\n",
      "\n",
      "0 features found and 0 ignored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.00s Warp feature \"otype\" not found in\n",
      "/Users/cody/github/csl/time_collocations/data/test/\n",
      "  0.00s Warp feature \"oslots\" not found in\n",
      "/Users/cody/github/csl/time_collocations/data/test/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Warp feature \"otext\" not found. Working without Text-API\n",
      "\n",
      "  0.00s Exporting 2 node and 2 edge and 0 config features to /Users/cody/github/csl/time_collocations/data/test:\n",
      "  0.00s VALIDATING oslots feature\n",
      "  0.15s maxSlot=     426584\n",
      "  0.15s maxNode=    1777974\n",
      "  0.45s OK: oslots is valid\n",
      "   |     0.10s T label                to /Users/cody/github/csl/time_collocations/data/test\n",
      "   |     0.82s T otype                to /Users/cody/github/csl/time_collocations/data/test\n",
      "   |     3.58s T oslots               to /Users/cody/github/csl/time_collocations/data/test\n",
      "   |     0.06s T role                 to /Users/cody/github/csl/time_collocations/data/test\n",
      "  5.01s Exported 2 node features and 2 edge features and 0 config features to /Users/cody/github/csl/time_collocations/data/test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuredir = '../data/test'\n",
    "\n",
    "meta = {'':{'source': 'https://github.com/etcbc/bhsa',\n",
    "            'origin': 'Made by the ETCBC of the Vrije Universiteit Amsterdam; edited by Cody Kingham',\n",
    "            'coreData':'BHSA',\n",
    "            'coreVersion':'c',},\n",
    "        'oslots': {'valueType':'int', \n",
    "                   'edgeValues':False},\n",
    "        'otype':{'valueType':'str'},\n",
    "        'role':{'edgeValues':True,\n",
    "                'valueType':'str', \n",
    "                'description':'role of the word in the chunk'},\n",
    "        'label':{'valueType':'str'},\n",
    "       }\n",
    "\n",
    "TFsave = Fabric(locations=featuredir)\n",
    "\n",
    "TFsave.save(nodeFeatures=nodeFeatures, edgeFeatures=edgeFeatures, metaData=meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Strategy\n",
    "\n",
    "The analysis below contains the exploratory stages of this examination, from which the strategy and process above has been derived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying Constructions\n",
    "\n",
    "Attempting to describe the most productive constructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token2results = collections.defaultdict(list)\n",
    "found_phrases = set()\n",
    "\n",
    "def show_progress(setA, setB):\n",
    "    lenA, lenB = len(setA), len(setB)\n",
    "    print(f'{lenA} / {lenB}\\t{round(lenA/lenB, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. prep + H + timeNoun + H + demonstrative/ordinal/other\n",
    "\n",
    "The ×‘.×”.×™×•×.×”.×”×•× construction is the most common with a relatively high DP score of (0.56), and there are numerous similar variants of this construction. Below I aim to represent this construction abstractly, with each of the pieces constructed with parts of speech fillers. I want to see how much of the data this construction accounts for, and I want to compare its distribution and use accross other categories and functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.51s 715 results\n",
      "\n",
      "696 / 3376\t0.21\n"
     ]
    }
   ],
   "source": [
    "hh_cx = A.search('''\n",
    "\n",
    "phrase2 function=Time\n",
    "    chunk label=prep\n",
    "    <: word lex=H language=Hebrew\n",
    "    <: word pdp=subs\n",
    "    <: word lex=H\n",
    "    <: word\n",
    "    /with/\n",
    "    pdp=prde\n",
    "    /or/\n",
    "    ls=ordn\n",
    "    /-/\n",
    "\n",
    "''')\n",
    "\n",
    "hh_name = 'prep_H_time_H_{}'\n",
    "token2results[hh_name] = hh_cx\n",
    "\n",
    "# log time construction object\n",
    "for result in hh_cx:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    named_slot = 'demon' if F.pdp.v(result[5]) == 'prde' else 'ordinal'\n",
    "    nodeFeatures['label'][node] = hh_name.format(named_slot)\n",
    "    edgeFeatures['oslot'][node] = tuple(L.d(result[1], 'word')) + result[2:]\n",
    "    edgeFeatures['role'][result[2]] = {'timenoun':node}\n",
    "    edgeFeatures['role'][result[1]] = {'orient':node}\n",
    "    edgeFeatures['role'][result[-1]] = {named_slot:node}\n",
    "\n",
    "# report progress\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(hh_cx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Ã¸ + H + timeNoun + H + demonstrative/ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.52s 35 results\n",
      "\n",
      "731 / 3376\t0.22\n"
     ]
    }
   ],
   "source": [
    "hh_cx = A.search('''\n",
    "\n",
    "phrase2 function=Time\n",
    "/without/\n",
    "    chunk label=prep\n",
    "/-/\n",
    "    word lex=H language=Hebrew\n",
    "    <: word pdp=subs\n",
    "    <: word lex=H\n",
    "    <: word\n",
    "    /with/\n",
    "    pdp=prde\n",
    "    /or/\n",
    "    ls=ordn\n",
    "    /-/\n",
    "\n",
    "''')\n",
    "\n",
    "hh_name = 'H_time_H_{}'\n",
    "token2results[hh_name] = hh_cx\n",
    "\n",
    "# log time construction object\n",
    "for result in hh_cx:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    named_slot = 'demon' if F.pdp.v(result[-1]) == 'prde' else 'ordinal'\n",
    "    nodeFeatures['label'][node] = hh_name.format(named_slot)\n",
    "    edgeFeatures['oslot'][node] = tuple(L.d(result[1], 'word')) + result[2:]\n",
    "    edgeFeatures['role'][result[2]] = {'timenoun':node}\n",
    "    edgeFeatures['role'][result[1]] = {'orient':node}\n",
    "    edgeFeatures['role'][result[-1]] = {named_slot:node}\n",
    "\n",
    "# report progress\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. H + timeNoun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.74s 216 results\n",
      "\n",
      "947 / 3376\t0.28\n"
     ]
    }
   ],
   "source": [
    "the_cx = A.search('''\n",
    "\n",
    "p:phrase2 function=Time\n",
    "    =: word lex=H language=Hebrew\n",
    "    <: w1:word pdp=subs\n",
    "p := w1\n",
    "\n",
    "''')\n",
    "\n",
    "the_cx_name = 'H_time'\n",
    "token2results[the_cx_name] = the_cx\n",
    "\n",
    "for result in the_cx:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = the_cx_name\n",
    "    edgeFeatures['oslot'][node] = L.d(result[0], 'word')\n",
    "    edgeFeatures['role'][result[2]] = {'timenoun':node}\n",
    "    edgeFeatures['role'][result[1]] = {'H':node}\n",
    "    \n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(the_cx, condenseType='sentence', extraFeatures='st')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Quantified Constructions (×ž×³×³)\n",
    "\n",
    "Time constructions with quantifiers seem to inherit the quantified NP construction, and there are thus relatively complex chains that are formed. These constructions are pre-processed into quantifier constructions in [quantifier_constructions.ipynb](preprocessing/quantifier_constructions.ipynb). The result is a new object, constructions, and constructions with a label of 'quantified_NP' are base units of constructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count Quantifier Construction Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenQuants(phrasenode):\n",
    "    '''\n",
    "    Generic tokenizer\n",
    "    for non-tagged constructions.\n",
    "    '''\n",
    "    \n",
    "    words = list(L.d(phrasenode, 'word'))\n",
    "    token = []\n",
    "    i = 0 \n",
    "    while i < len(words):\n",
    "        word = words[i]\n",
    "        i += 1\n",
    "        \n",
    "        construct = next((c for c in L.u(word, 'chunk') if F.label.v(c) != 'prep'), 0)\n",
    "\n",
    "        # replace quantified cx\n",
    "        if construct:\n",
    "            \n",
    "            if F.label.v(construct) in {'quant_NP', 'quant_NP_chain'}:\n",
    "            \n",
    "                construct = sorted((len(L.d(cx, 'word')), cx)\n",
    "                                    for cx in L.u(word, 'chunk')\n",
    "                                    if 'quant_NP' in F.label.v(cx))[-1][1]\n",
    "                token.append('×ž×“×³×³')\n",
    "\n",
    "            elif F.label.v(construct) == 'quant':\n",
    "                token.append('×ž×³×³')\n",
    "                \n",
    "            # skip subsequent words in the construction\n",
    "            i += len(L.d(construct, 'word'))-1\n",
    "\n",
    "            \n",
    "        elif F.lex.v(word) == 'H':\n",
    "            token.append('×”')\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            if token and token[0] == '×ž×“×³×³': # ignore additional modifiers\n",
    "                token = ['×ž×“×³×³']\n",
    "                i = len(words)\n",
    "            \n",
    "            else:\n",
    "                token.append(F.g_cons_utf8.v(word))\n",
    "            \n",
    "    return '.'.join(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.44s 165 results\n",
      "  1.54s 165 results\n",
      "  0.81s 54 results\n",
      "\n",
      " 202 phrases accounted for in these loops\n"
     ]
    }
   ],
   "source": [
    "qmeta = [] # put all construction data here\n",
    "count_quants = collections.Counter()\n",
    "\n",
    "prep_time_l_time = A.search('''\n",
    "\n",
    "sentence\n",
    "    chunk label=prep\n",
    "    <: word st=c ls#card\n",
    "    <1: c1:chunk label=quant_NP|quant_NP_chain|quant\n",
    "    /with/\n",
    "    :> word pdp=art\n",
    "    /or/\n",
    "    :> word st=c ls#card\n",
    "    /-/\n",
    "    \n",
    "    /without/\n",
    "    chunk\n",
    "        ..\n",
    "    /-/\n",
    "        word\n",
    "    w1:word lex=L language=Hebrew\n",
    "    <: word sem_set#prep\n",
    "\n",
    "    c1 <: w1\n",
    "''') \n",
    "\n",
    "qmeta.append({'results': prep_time_l_time,\n",
    "              'label':'prep_q[time]_L',\n",
    "              'phrase2_ref': 1,\n",
    "              'oslot_ends': (1, 6),\n",
    "              'semroles':{1:'orient',\n",
    "                          2:'time',\n",
    "                          3:'quantNP',\n",
    "                          5:'L',\n",
    "                          6:'reference'\n",
    "                          }\n",
    "              })\n",
    "\n",
    "    \n",
    "prep_l_time = A.search('''\n",
    "\n",
    "sentence\n",
    "    chunk label=prep\n",
    "    <: c1:chunk label=quant_NP|quant_NP_chain|quant\n",
    "\n",
    "    /without/\n",
    "    chunk\n",
    "        ..\n",
    "    /-/\n",
    "        word\n",
    "    w1:word lex=L language=Hebrew\n",
    "    <: word sem_set#prep\n",
    "\n",
    "    c1 <: w1\n",
    "''') \n",
    "\n",
    "\n",
    "qmeta.append({'results': prep_l_time,\n",
    "              'label':'prep_q[time]_L',\n",
    "              'phrase2_ref': 1,\n",
    "              'oslot_ends': (1, 5),\n",
    "              'semroles':{1:'orient',\n",
    "                          2:'quantNP',\n",
    "                          4:'L',\n",
    "                          5:'reference'\n",
    "                          }\n",
    "              })\n",
    "\n",
    "\n",
    "# This pattern is very long because \n",
    "# there are restrictions needed to ensure that\n",
    "# the quantified NP time phrase is truly\n",
    "# standing on its own without contributing\n",
    "# to a larger construction\n",
    "prep_qTime = A.search('''\n",
    "\n",
    "sentence\n",
    "    phrase2 function=Time\n",
    "        chunk label=prep\n",
    "        /without/\n",
    "        phrase2\n",
    "            chunk label=quant_NP|quant_NP_chain|quant\n",
    "            <: ..\n",
    "        /-/\n",
    "        /without/\n",
    "        phrase2\n",
    "            phrase_atom typ=PP\n",
    "            <: ..\n",
    "        /-/\n",
    "            =: word lex#>T\n",
    "        \n",
    "        <: chunk label=quant_NP|quant_NP_chain\n",
    "        /without/\n",
    "        chunk\n",
    "            ..\n",
    "        /-/\n",
    "        /without/\n",
    "        ..\n",
    "        <: word pdp=prep language=Hebrew\n",
    "        /-/\n",
    "        /without/\n",
    "        phrase2\n",
    "            ..\n",
    "            < word pdp=prep\n",
    "        /-/\n",
    "        /without/\n",
    "        sentence\n",
    "            ..\n",
    "            < phrase function=Time typ=PP\n",
    "        /-/\n",
    "\n",
    "''') \n",
    "token = 'prep_qNP'\n",
    "\n",
    "qmeta.append({'results': prep_qTime,\n",
    "              'label':'prep_qNP',\n",
    "              'phrase2_ref': 2,\n",
    "              'oslot_ends': (2, 4),\n",
    "              'semroles':{2:'orient',\n",
    "                          4:'quantNP',\n",
    "                          }\n",
    "              })    \n",
    "    \n",
    "# PUT NEW LOOP HERE!\n",
    "    \n",
    "these_phrases = set()\n",
    "\n",
    "for query in qmeta:\n",
    "    token2results[query['label']] = query['results']\n",
    "    \n",
    "    for res in query['results']:\n",
    "        count_quants[query['label']] += 1\n",
    "\n",
    "        # update phrase2 tracking\n",
    "        phrase2 = L.u(res[query['phrase2_ref']], 'phrase2')[0]\n",
    "        found_phrases.add(phrase2)\n",
    "        these_phrases.add(phrase2)\n",
    "        \n",
    "        # map to CX object\n",
    "        node += 1\n",
    "        nodeFeatures['otype'][node] = 'construction'\n",
    "        nodeFeatures['label'][node] = query['label']\n",
    "        start, end = query['oslot_ends']\n",
    "        edgeFeatures['oslot'][node] = flattenNodes(res[start:end+1])\n",
    "        for i, semrole in query['semroles'].items():\n",
    "            edgeFeatures['role'][res[i]] = {semrole:node}\n",
    "            \n",
    "print('\\n', len(these_phrases), 'phrases accounted for in these loops')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1109 / 3376\t0.33\n"
     ]
    }
   ],
   "source": [
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remaining cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.83s 1005 results\n",
      "\n",
      "phrases added here:\t339\n",
      "phrases NOT added:\t49\n",
      "\n",
      "TOTAL progress\n",
      "1448 / 3376\t0.43\n"
     ]
    }
   ],
   "source": [
    "remaining2res = collections.defaultdict(list)\n",
    "\n",
    "quant_cx = A.search('''\n",
    "\n",
    "phrase2\n",
    "    phrase function=Time\n",
    "        <nhead- word pdp=subs\n",
    "        word ls=card language=Hebrew\n",
    " \n",
    "''')\n",
    "    \n",
    "these_phrases = set()\n",
    "unknown_phrases = set()\n",
    "    \n",
    "for result in quant_cx:\n",
    "    \n",
    "    if result[0] in found_phrases:\n",
    "        continue\n",
    "    \n",
    "    ph_token = tokenQuants(result[0])\n",
    "    \n",
    "    # case-by-case basis constructions handled here\n",
    "    # these are constructions where it is easier to \n",
    "    # take the subset of phrases  NOT yet accounted for\n",
    "    # since the other cases are by now filtered out\n",
    "    \n",
    "    # handle durative cases\n",
    "    if ph_token == '×ž×“×³×³':\n",
    "                \n",
    "        ph_token = 'Ã¸_quantNP'\n",
    "        found_phrases.add(result[0])\n",
    "        these_phrases.add(result[0])\n",
    "        \n",
    "        node += 1\n",
    "        nodeFeatures['otype'][node] = 'construction'\n",
    "        nodeFeatures['label'][node] = ph_token\n",
    "        edgeFeatures['oslot'][node] = L.d(result[0], 'word')\n",
    "        edgeFeatures['role'][result[2]] = {'timenoun':node}\n",
    "    \n",
    "    else:\n",
    "        unknown_phrases.add(result[0])\n",
    "    \n",
    "    # all other cases just count them\n",
    "    count_quants[ph_token] += 1\n",
    "    remaining2res[ph_token].append(result)\n",
    "    \n",
    "print()\n",
    "print(f'phrases added here:\\t{len(these_phrases)}')\n",
    "print(f'phrases NOT added:\\t{len(unknown_phrases)}')\n",
    "\n",
    "print('\\nTOTAL progress')\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect What Is There"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_quants = pd.DataFrame(count_quants.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "showresult = 0\n",
    "showme = remaining2res['×‘.×ž×“×³×³']\n",
    "\n",
    "#A.show(showme, extraFeatures='st', condenseType='sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_quants.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ã¸_quantNP</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prep_q[time]_L</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prep_qNP</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>×ž×“×³×³.×ž×“×³×³</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>×‘.×ž×³×³.×‘×•</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>×‘.×ž×³×³.×‘×•.×•.×‘.×ž×³×³.×‘×•</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>××—×¨.×”.×ž×‘×•×œ.×ž×“×³×³</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>×¢×“.×¢×¨×‘.×ž×“×³×³</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>×‘.×™×•×.×ž×“×³×³</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>××ª.×ž×³×³.×”.×™×•×.×•.××ª.×ž×³×³.×”.×œ×™×œ×”</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>×ž×³×³.×œ.×ž×“×³×³</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>×‘.×ž×“×³×³</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>×ž.×™×•×.×œ.×™×•×.×•.×ž.×—×“×©×.×œ.×ž×“×³×³</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>×ž×³×³</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>×ž×³×³.×‘.×”.×©×× ×”</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>×ž×¡×¤×¨.×”.×™×ž×™×.×ž×“×³×³</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>×œ.×”.×©××‘×ª×•×ª.×•.×œ.×”.×—×“×©××™×.×•.×œ.×”.×ž×•×¢×“×•×ª.×ž×“×³×³.×‘.×”....</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>×œ.×”.×™×•×.×ž×“×³×³</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>×ž.×§×¦×”.×ž×“×³×³</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>×‘.×”.×©×× ×”.×”.×ž×³×³.×‘.×™×¨×—.×‘×•×œ</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>××—×¨×™.×ž×•×ª.×™×”×•××©×.×‘×Ÿ.×™×”×•××—×–.×ž×œ×š.×™×©×‚×¨××œ.×ž×“×³×³</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>××—×¨×™.×–××ª.×ž×“×³×³</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>×™×ž×™×.×¨×‘×™×.×ž×“×³×³</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>×‘.×ž×“×³×³.×‘×•.×‘.×”.×™×•×</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>××—×¨×™.×”.×ž×“×³×³</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>×œ.×ž×“×³×³</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>××—×¨×™.×ž×•×ª.×™×•××©×.×‘×Ÿ.×™×”×•××—×–.×ž×œ×š.×™×©×‚×¨××œ.×ž×“×³×³</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>×œ.×™×ž×™×.×¢×•×“.×ž×³×³</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>××ª.×ž×“×³×³</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>×™×•×ž×.×•.×œ×™×œ×”.×ž×“×³×³</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>××—×¨×™.×ž×•×ª.×ž×“×³×³.××”×¨×Ÿ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>×ž.×§×¥.×ž×“×³×³.×‘.×ž×¢×“.×©×× ×ª.×”.×©××ž×˜×”</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>×‘.×™×ž×™.×¤×œ×©××ª×™×.×ž×“×³×³</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>×”.×™×•×.×ž×“×³×³</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>×”.×ž×“×³×³</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>×‘.×™×ž×™.×“×•×“.×ž×“×³×³.×©×× ×”.××—×¨×™.×©×× ×”</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>×‘.×©×× ×ª.×ž×³×³</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>×‘.×ž×³×³.×‘.×”.×—×“×©×</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>×‘.×—×“×©×.×›×¡×œ×•.×©×× ×ª.×ž×³×³</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>×‘.×—×“×©×.× ×™×¡×Ÿ.×©×× ×ª.×ž×³×³.×œ.××¨×ª×—×©××¡×ª×.×”.×ž×œ×š</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>×‘×™×Ÿ.×ž×“×³×³</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0    1\n",
       "0                                           Ã¸_quantNP  339\n",
       "1                                      prep_q[time]_L  330\n",
       "2                                            prep_qNP   54\n",
       "3                                           ×ž×“×³×³.×ž×“×³×³    8\n",
       "4                                            ×‘.×ž×³×³.×‘×•    8\n",
       "5                                 ×‘.×ž×³×³.×‘×•.×•.×‘.×ž×³×³.×‘×•    8\n",
       "6                                     ××—×¨.×”.×ž×‘×•×œ.×ž×“×³×³    6\n",
       "7                                         ×¢×“.×¢×¨×‘.×ž×“×³×³    6\n",
       "8                                          ×‘.×™×•×.×ž×“×³×³    4\n",
       "9                        ××ª.×ž×³×³.×”.×™×•×.×•.××ª.×ž×³×³.×”.×œ×™×œ×”    4\n",
       "10                                         ×ž×³×³.×œ.×ž×“×³×³    4\n",
       "11                                             ×‘.×ž×“×³×³    4\n",
       "12                        ×ž.×™×•×.×œ.×™×•×.×•.×ž.×—×“×©×.×œ.×ž×“×³×³    4\n",
       "13                                                ×ž×³×³    4\n",
       "14                                       ×ž×³×³.×‘.×”.×©×× ×”    3\n",
       "15                                   ×ž×¡×¤×¨.×”.×™×ž×™×.×ž×“×³×³    3\n",
       "16  ×œ.×”.×©××‘×ª×•×ª.×•.×œ.×”.×—×“×©××™×.×•.×œ.×”.×ž×•×¢×“×•×ª.×ž×“×³×³.×‘.×”....    3\n",
       "17                                       ×œ.×”.×™×•×.×ž×“×³×³    2\n",
       "18                                         ×ž.×§×¦×”.×ž×“×³×³    2\n",
       "19                           ×‘.×”.×©×× ×”.×”.×ž×³×³.×‘.×™×¨×—.×‘×•×œ    2\n",
       "20          ××—×¨×™.×ž×•×ª.×™×”×•××©×.×‘×Ÿ.×™×”×•××—×–.×ž×œ×š.×™×©×‚×¨××œ.×ž×“×³×³    2\n",
       "21                                      ××—×¨×™.×–××ª.×ž×“×³×³    2\n",
       "22                                     ×™×ž×™×.×¨×‘×™×.×ž×“×³×³    2\n",
       "23                                  ×‘.×ž×“×³×³.×‘×•.×‘.×”.×™×•×    2\n",
       "24                                        ××—×¨×™.×”.×ž×“×³×³    2\n",
       "25                                             ×œ.×ž×“×³×³    2\n",
       "26           ××—×¨×™.×ž×•×ª.×™×•××©×.×‘×Ÿ.×™×”×•××—×–.×ž×œ×š.×™×©×‚×¨××œ.×ž×“×³×³    2\n",
       "27                                     ×œ.×™×ž×™×.×¢×•×“.×ž×³×³    1\n",
       "28                                            ××ª.×ž×“×³×³    1\n",
       "29                                   ×™×•×ž×.×•.×œ×™×œ×”.×ž×“×³×³    1\n",
       "30                                 ××—×¨×™.×ž×•×ª.×ž×“×³×³.××”×¨×Ÿ    1\n",
       "31                       ×ž.×§×¥.×ž×“×³×³.×‘.×ž×¢×“.×©×× ×ª.×”.×©××ž×˜×”    1\n",
       "32                                 ×‘.×™×ž×™.×¤×œ×©××ª×™×.×ž×“×³×³    1\n",
       "33                                         ×”.×™×•×.×ž×“×³×³    1\n",
       "34                                             ×”.×ž×“×³×³    1\n",
       "35                      ×‘.×™×ž×™.×“×•×“.×ž×“×³×³.×©×× ×”.××—×¨×™.×©×× ×”    1\n",
       "36                                         ×‘.×©×× ×ª.×ž×³×³    1\n",
       "37                                     ×‘.×ž×³×³.×‘.×”.×—×“×©×    1\n",
       "38                               ×‘.×—×“×©×.×›×¡×œ×•.×©×× ×ª.×ž×³×³    1\n",
       "39             ×‘.×—×“×©×.× ×™×¡×Ÿ.×©×× ×ª.×ž×³×³.×œ.××¨×ª×—×©××¡×ª×.×”.×ž×œ×š    1\n",
       "40                                           ×‘×™×Ÿ.×ž×“×³×³    1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_quants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Qualitative Quantifiers (Ã¸)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.62s 191 results\n",
      "\n",
      "1625 / 3376\t0.48\n"
     ]
    }
   ],
   "source": [
    "null_qq = A.search('''\n",
    "\n",
    "phrase2 function=Time\n",
    "/without/\n",
    "    chunk label=prep\n",
    "/-/\n",
    "    word sem_set=quant ls#card language=Hebrew\n",
    "    <1: word pdp=subs ls#card\n",
    "    /with/\n",
    "    :> word pdp=art\n",
    "    /or/\n",
    "    :> word sem_set=quant ls#card\n",
    "    /-/\n",
    "''')\n",
    "\n",
    "\n",
    "null_qq_name = 'Ã¸_qualityQuant_NP'\n",
    "token2results[null_qq_name] = null_qq\n",
    "\n",
    "for result in null_qq:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = null_qq_name\n",
    "    edgeFeatures['oslot'][node] = result\n",
    "    edgeFeatures['role'][result[2]] = {'timenoun':node}\n",
    "    edgeFeatures['role'][result[1]] = {'qualQuant':node}\n",
    "\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(null_qq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Dual-Endings\n",
    "\n",
    "Nouns that are otherwise unmarked for number can be marked with a dual ending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.95s 25 results\n",
      "\n",
      "1650 / 3376\t0.49\n"
     ]
    }
   ],
   "source": [
    "timeDual = A.search('''\n",
    "\n",
    "phrase2 function=Time\n",
    "    =: chunk label=prep\n",
    "    <1: word nu=du ls#card\n",
    "    /with/\n",
    "    :> word pdp=art\n",
    "    /or/\n",
    "    :> chunk label=prep\n",
    "    /-/\n",
    "    \n",
    "''')\n",
    "\n",
    "tDual_name = 'prep_timeDual'\n",
    "token2results[tDual_name] = timeDual\n",
    "\n",
    "for result in timeDual:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = tDual_name\n",
    "    edgeFeatures['oslot'][node] = flattenNodes(result[1:])\n",
    "    edgeFeatures['role'][result[2]] = {'timenoun':node}\n",
    "    edgeFeatures['role'][result[1]] = {'orient':node}\n",
    "    \n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. PP + NP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.79s 665 results\n",
      "  2.88s 460 results\n",
      "\n",
      "2628 / 3376\t0.78\n"
     ]
    }
   ],
   "source": [
    "pp_np = []\n",
    "\n",
    "pp_np_query = '''\n",
    "\n",
    "p:phrase2 function=Time\n",
    "/without/\n",
    "    word\n",
    "    /with/\n",
    "    <mother- clause\n",
    "    /or/\n",
    "    sem_set=quant\n",
    "    /or/\n",
    "    nu=du\n",
    "    /or/\n",
    "    pdp=prde|conj\n",
    "    /-/\n",
    "/-/\n",
    "    =: chunk label=prep\n",
    "    /without/\n",
    "    phrase2\n",
    "        ..\n",
    "        << word pdp=prep\n",
    "    /-/\n",
    "    \n",
    "    {option}\n",
    "    \n",
    "    <: n:word pdp=subs ls#card sem_set#prep language=Hebrew\n",
    "'''\n",
    "\n",
    "for option in {'', '<: word pdp=art'}:\n",
    "    pp_np.extend(A.search(pp_np_query.format(option=option)))\n",
    "\n",
    "ppnp_name = 'prep_time'\n",
    "token2results[ppnp_name] = pp_np\n",
    "\n",
    "for result in pp_np:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = ppnp_name\n",
    "    edgeFeatures['oslot'][node] = L.d(result[0], 'word')\n",
    "    edgeFeatures['role'][result[-1]] = {'timenoun':node}\n",
    "    edgeFeatures['role'][result[1]] = {'orient':node}\n",
    "    \n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.shuffle(pp_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(pp_np, extraFeatures='st', condensed=False, condenseType='clause')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. prep + noun + inf_verb_clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.73s 114 results\n",
      "\n",
      "2736 / 3376\t0.81\n"
     ]
    }
   ],
   "source": [
    "pp_np_cl = A.search('''\n",
    "\n",
    "phrase2 function=Time\n",
    "    =: chunk label=prep\n",
    "    w1:word pdp=subs language=Hebrew\n",
    "    \n",
    "w1 \n",
    "<mother- clause\n",
    "    \n",
    "''')\n",
    "\n",
    "\n",
    "pptc_name = 'prep_time_clause'\n",
    "token2results[pptc_name] = pp_np_cl\n",
    "\n",
    "for result in pp_np_cl:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = pptc_name\n",
    "    edgeFeatures['oslot'][node] = flattenNodes(result)\n",
    "    edgeFeatures['role'][result[2]] = {'timenoun':node}\n",
    "    edgeFeatures['role'][result[1]] = {'orient':node}\n",
    "    edgeFeatures['role'][result[-1]] = {'event':node}\n",
    "\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 prep + inrg\n",
    "\n",
    "The preposition + interrogative construction is related to the prep+NP construction. The interrogative particle is extended into the position of a noun. In many cases, these nouns are habitually associated with temporal question phrases, e.g. ×ž×ª×™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.19s 39 results\n",
      "\n",
      "2775 / 3376\t0.82\n"
     ]
    }
   ],
   "source": [
    "prep_inrg = A.search('''\n",
    "\n",
    "p:phrase2 function=Time\n",
    "    =: chunk label=prep\n",
    "    <: w1:word pdp=inrg language=Hebrew\n",
    "\n",
    "''')\n",
    "\n",
    "pp_inrg_name = 'prep_timeQuestion'\n",
    "token2results[pp_inrg_name] = prep_inrg\n",
    "\n",
    "for result in prep_inrg:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = pp_inrg_name\n",
    "    edgeFeatures['oslot'][node] = L.d(result[0], 'word')\n",
    "    edgeFeatures['role'][result[2]] = {'timeQuestion':node}\n",
    "    edgeFeatures['role'][result[1]] = {'orient':node}\n",
    "\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.shuffle(prep_inrg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(prep_inrg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 prep + pronominal suffix\n",
    "\n",
    "This construction is also related to the prep+NP, especially in the sense the the NP often takes a suffix when refering to event-type nouns. The cases below consist of time constructions where a preposition is the only item, and a pronominal suffix is attached to it. These cases seem to involve some existential sense related to a person: \"after me\", \"after them\" i.e. \"after [I exist]\". In fact, the preposition seems to play a kind of double duty in theses cases: both as a sort of noun and as a preposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.77s 34 results\n",
      "\n",
      "2809 / 3376\t0.83\n"
     ]
    }
   ],
   "source": [
    "prep_sffx = A.search('''\n",
    "\n",
    "p:phrase2 function=Time\n",
    "    w1:word pdp=prep prs#absent\n",
    "\n",
    "p =: w1\n",
    "p := w1\n",
    "''')\n",
    "\n",
    "prep_sffx_name = 'prep_suffix'\n",
    "token2results[prep_sffx_name] = prep_sffx\n",
    "\n",
    "for result in prep_sffx:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = prep_sffx_name\n",
    "    edgeFeatures['oslot'][node] = L.d(result[0], 'word')\n",
    "    edgeFeatures['role'][result[1]] = {'orientExist':node}\n",
    "\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.shuffle(prep_sffx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(prep_sffx, condensed=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. \"Adverb\" Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.41s 179 results\n",
      "\n",
      "2988 / 3376\t0.89\n"
     ]
    }
   ],
   "source": [
    "advb = A.search('''\n",
    "\n",
    "p:phrase2 function=Time\n",
    "    w1:word pdp=advb lex#>K|>Z|<TH|KN language=Hebrew\n",
    "\n",
    "w1 =: p\n",
    "w1 := p\n",
    "''')\n",
    "\n",
    "\n",
    "advb_name = 'timeAdvb'\n",
    "token2results[advb_name] = advb\n",
    "\n",
    "for result in advb:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = advb_name\n",
    "    edgeFeatures['oslot'][node] = result\n",
    "    edgeFeatures['role'][result[0]] = {'timenoun':node}\n",
    "\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(advb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show([res for res in advb if F.lex.v(res[1]) == '>XR/'], condensed=False, condenseType='sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. timeNoun Only\n",
    "\n",
    "If a timenoun solely occupies the time construction it is nearly always morphologically marked in some way. Two cases are seen: time nouns with dual endings (indicating a specified segment of time), and time nouns with plural endings (indicating an unmarked duration). While different in function, these time nouns are similar in form, and they especially resemble the adverbials recognized above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. PP/NP Repetition\n",
    "\n",
    "The repetition of the same phrase/noun twice is used to indicate repetitive, cyclic time. This takes advantage of the repeating noun construction used to represent plurality, but the function is extended in the time function. This highlights how plurality can be an indicator of time duration.\n",
    "\n",
    "This analysis requires some hand-coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 pp results...\n",
      "9 nn results...\n"
     ]
    }
   ],
   "source": [
    "repeats = []\n",
    "\n",
    "pp_pp = '''\n",
    "\n",
    "phrase2 function=Time\n",
    "    chunk label=prep\n",
    "    {option}\n",
    "    <: word pdp=subs\n",
    "    <: chunk label=prep\n",
    "    {option}\n",
    "    <: word pdp=subs\n",
    "'''\n",
    "\n",
    "pp_pp = [res for opt in ('', '<: word pdp=art')\n",
    "            for res in A.search(pp_pp.format(option=opt), silent=True)]\n",
    "\n",
    "for res in pp_pp:\n",
    "    prep1, prep2 = (c for c in res if F.otype.v(c) == 'chunk')\n",
    "    word1, word2 = (w for w in res if F.pdp.v(w) != 'art' and w not in {prep1, prep2, res[0]})\n",
    "    prepT1, prepT2 = [T.text(prep, fmt='text-orig-plain', descend=True) for prep in (prep1, prep2)]\n",
    "    wordT1, wordT2 = [F.g_cons_utf8.v(w) for w in (word1, word2)]\n",
    "    \n",
    "    if all([prepT1 == prepT2,\n",
    "            wordT1 == wordT2]):\n",
    "        repeats.append(res)\n",
    "        \n",
    "print(f'{len(res)} pp results...')\n",
    "\n",
    "\n",
    "np_np = A.search(f'''\n",
    "\n",
    "phrase2 function=Time\n",
    "/without/\n",
    "    chunk label=prep\n",
    "/-/\n",
    "    word\n",
    "    <: word    \n",
    "    \n",
    "''', silent=True)\n",
    "\n",
    "npnpct = 0\n",
    "for res in np_np:\n",
    "    \n",
    "    word1, word2 = F.g_cons_utf8.v(res[1]), F.g_cons_utf8.v(res[2])\n",
    "    \n",
    "    if word1 == word2:\n",
    "        repeats.append(res)\n",
    "        npnpct += 1\n",
    "        \n",
    "print(f'{npnpct} nn results...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3012 / 3376\t0.89\n"
     ]
    }
   ],
   "source": [
    "trepeat = 'timeRepeat'\n",
    "token2results[trepeat] = repeats\n",
    "\n",
    "for result in repeats:\n",
    "    found_phrases.add(result[0])\n",
    "    node += 1\n",
    "    nodeFeatures['otype'][node] = 'construction'\n",
    "    nodeFeatures['label'][node] = trepeat\n",
    "    edgeFeatures['oslot'][node] = result\n",
    "#     edgeFeatures['semrole'][result[0]] = {'timenoun':node}\n",
    "\n",
    "print()\n",
    "show_progress(found_phrases, time_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random.shuffle(repeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(repeats, condensed=False, condenseType='phrase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATUS CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prep_time</th>\n",
       "      <td>1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_H_time_H_{}</th>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_time</th>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ã¸_qualityQuant_NP</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timeAdvb</th>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_q[time]_L</th>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_time_clause</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_qNP</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_timeQuestion</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>H_time_H_{}</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_suffix</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep_timeDual</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timeRepeat</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count\n",
       "prep_time           1125\n",
       "prep_H_time_H_{}     715\n",
       "H_time               216\n",
       "Ã¸_qualityQuant_NP    191\n",
       "timeAdvb             179\n",
       "prep_q[time]_L       165\n",
       "prep_time_clause     114\n",
       "prep_qNP              54\n",
       "prep_timeQuestion     39\n",
       "H_time_H_{}           35\n",
       "prep_suffix           34\n",
       "prep_timeDual         25\n",
       "timeRepeat            25"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = dict((token, len(res)) for token, res in token2results.items())\n",
    "stats = pd.DataFrame.from_dict(stats, orient='index', columns=['count'])\n",
    "stats.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2917"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_tp = time_phrases-found_phrases\n",
    "remaining_patterns = collections.Counter()\n",
    "remain2result = collections.defaultdict(list)\n",
    "\n",
    "for tp in remaining_tp:\n",
    "    token = tokenPhrase(tp, tokener=tokenWord)\n",
    "    remaining_patterns[token] += 1\n",
    "    remain2result[token].append(L.d(tp, 'word'))\n",
    "    \n",
    "remaining_patterns = pd.DataFrame.from_dict(dict(remaining_patterns.most_common()), orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>subs</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.subs.subs</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.subs.conj.subs</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subs.adjv</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.subs.ha.subs.ha.prde</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>advb.conj.advb</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.subs.prep.subs</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subs.subs</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.ha.subs.conj.prep.ha.subs</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prep.advb</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 0\n",
       "subs                            31\n",
       "prep.subs.subs                  24\n",
       "prep.subs.conj.subs             20\n",
       "subs.adjv                       19\n",
       "prep.subs.ha.subs.ha.prde       19\n",
       "advb.conj.advb                  19\n",
       "prep.subs.prep.subs             15\n",
       "subs.subs                       14\n",
       "prep.ha.subs.conj.prep.ha.subs  10\n",
       "prep.advb                        8"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conj_tags = [t for t in remaining_patterns.index if 'conj' in t]\n",
    "\n",
    "remaining_patterns.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show(remain2result['subs'], condenseType='sentence', extraFeatures='sem_set ls nu st')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(res for res in )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chained PP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.60s 178 results\n"
     ]
    }
   ],
   "source": [
    "missingp2 = set(ph for ph in F.otype.s('phrase2') if ph not in found_phrases)\n",
    "\n",
    "t = A.search('''\n",
    "\n",
    "missingphrase2 function=Time\n",
    "    construction label=prep\n",
    "    << construction label=prep\n",
    "\n",
    "''', sets={'missingphrase2':missingp2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A.show([L.d(ph[0], 'word') for ph in t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "primitives\n",
    "\n",
    "* NP chunks â€” chunk from head to head **[head mod mod mod CONJ head mod]**, split on conj (conjunction) or **[head mod mod head mod]** split on head.\n",
    "    * have to account for \"prefixed\" entities: namely definite article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other cases of H+noun+H+modifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A.show(A.search('''\n",
    "\n",
    "# phrase2 function=Time\n",
    "#     word lex=H\n",
    "#     <: word pdp=subs\n",
    "#     <: word lex=H\n",
    "#     <: word ls#ordn pdp#prde\n",
    "\n",
    "# '''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Degree of Dispersion *DP*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # count all phrase tokens in all books\n",
    "# phrase_tokens = collections.defaultdict(lambda:collections.Counter())\n",
    "\n",
    "# for phrase in F.otype.s('phrase'):\n",
    "#     book, chapter, verse = T.sectionFromNode(phrase)\n",
    "#     phrase_tokens[book][tokenPhrase(phrase)] += 1\n",
    "    \n",
    "# phrase_tokens = pd.DataFrame(phrase_tokens).fillna(0)\n",
    "\n",
    "# phrase_tokens.shape\n",
    "\n",
    "# expected_prop = phrase_tokens.sum() / phrase_tokens.sum().sum()\n",
    "# observed_prop = time_tokens.div(time_tokens.sum(1), axis=0)\n",
    "# prop_diffs = abs(expected_prop-observed_prop)\n",
    "# dp = 1-pd.DataFrame(prop_diffs.sum(1) / 2, columns=['DP'])\n",
    "\n",
    "# time_dp_total = pd.concat((dp, time_tokens.sum(1)), axis=1)\n",
    "# time_dp_total.columns = ('DP', 'Total')\n",
    "# time_dp_total = time_dp_total[['Total', 'DP']]\n",
    "\n",
    "# time_dp_total.sort_values(by='Total', ascending=False).head(20)\n",
    "\n",
    "# dp.sort_values(ascending=False, by='DP').head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,6))\n",
    "# plt.plot(sorted(dp.values, reverse=True), color='darkblue')\n",
    "# plt.xlabel('Rank', size=18)\n",
    "# plt.ylabel('DP', size=18)\n",
    "# plt.title('DP Score by Token Rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8,6))\n",
    "# plt.plot(sorted(time_tokens.sum(1).values, reverse=True), color='darkblue')\n",
    "# plt.xlabel('Rank', size=18)\n",
    "# plt.ylabel('Frequency', size=18)\n",
    "# plt.title('Token Frequency by Rank')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
